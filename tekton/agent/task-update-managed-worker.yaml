apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: update-managed-worker
spec:
  params:
    - name: kata_directory
      default: 'kata-deploy'
    - name: update_agent
      default: 'true'
    - name: update_kata
      default: 'false'
    - name: clusterName
    - name: deployBaseImage
      default: us.icr.io/opentoolchain/cd-deploy-base:deploy
    - name: region
    - name: skipDeploy
      default: 'false'
    - name: target_domain
      default: 'devops.cloud.ibm.com'
    - name: set_worker_offline
      default: 'true'
    - name: run_commands
      default: 'false'
  stepTemplate:
    env:
      - name: API
        valueFrom:
          configMapKeyRef:
            name: cd-config
            key: API
      - name: API_KEY
        valueFrom:
          secretKeyRef:
            name: cd-secret
            key: DEPLOY_API_KEY
  workspaces:
    - name: task-pvc
      mountPath: /workspace
  steps:
    - name: deploy
      image: $(params.deployBaseImage)
      imagePullPolicy: IfNotPresent
      env:
        - name: UPDATE_KATA
          value: $(params.update_kata)
        - name: UPDATE_AGENT
          value: $(params.update_agent)
        - name: KATA_DIRECTORY
          value: $(params.kata_directory)
        - name: SKIP
          value: $(params.skipDeploy)
        - name: CLUSTER_NAME
          value: $(params.clusterName)
        - name: REGION
          value: $(params.region)
        - name: TARGET_DOMAIN
          value: $(params.target_domain)
        - name: SET_WORKER_OFFLINE
          value: $(params.set_worker_offline)
        - name: RUN_COMMANDS
          value: $(params.run_commands)
      workingDir: /workspace
      command: ['/bin/bash', '-c']
      args:
        - |
          export HOME=/root
          [ -f /root/.nvm/nvm.sh ] && source /root/.nvm/nvm.sh
          set -e
          if [ "${SKIP}" == true ]; then
            echo "Skipping Deploy"
            exit 0
          fi

          ibmcloud config --check-version=false
          ibmcloud plugin install -f container-service
          ibmcloud login -a ${API} -r ${REGION} --apikey ${API_KEY}
          ibmcloud ks cluster config --cluster ${CLUSTER_NAME}

          echo "Current managed worker state:"
          echo ${CLUSTER_NAME}
          kubectl describe workeragents
          kubectl get deployments -o wide -n tekton-pipelines
          kubectl get ds kata-deploy -o wide -n kube-system

          if [[ "$SET_WORKER_OFFLINE" == "true" ]]
          then
            kubectl patch workeragent $(kubectl get workeragents.devops.cloud.ibm.com -oname | sed "s/.*\///") --type='merge' -p '{"spec": {"paused": true}}'
            while kubectl get namespaces -l app=workeragent | grep pw; do sleep 10; done
          fi

          if [[ "$RUN_COMMANDS" != "false" ]]
          then
            eval $RUN_COMMANDS
          fi

          if [[ "$UPDATE_KATA" == "true" ]]
          then
            echo Comparing kata versions...
            target=$(yq r config/200-kata-deploy.yaml 'spec.template.spec.containers[0].image')
            current=$(kubectl get ds -n kube-system kata-deploy -o json | jq -r .spec.template.spec.containers[0].image)
            echo Current version = $current
            echo Target version = $target
            if ! [[ $current == $target ]] 
            then
              echo Update required... updating kata version
              kubectl patch workeragent $(kubectl get workeragents.devops.cloud.ibm.com -oname | sed "s/.*\///") --type='merge' -p '{"spec": {"paused": true}}'
              while kubectl get namespaces -l app=workeragent | grep pw; do sleep 10; done
              kubectl label node --all kata-deploy-
              while kubectl -n kube-system get pod | grep kata; do sleep 10; done
              kubectl apply -f ${KATA_DIRECTORY}/config/
              kubectl label node --all kata-deploy=true
              sleep 15
            fi
          fi

          if [[ "$UPDATE_AGENT" == "true" ]]
          then
            kubectl apply --filename "https://private-worker-service.${REGION}.${TARGET_DOMAIN}/update"
            sleep 10
            updaterPod=$(kubectl get pods | grep agent-updater | awk '{ print $1 }')
            echo "Waiting for pod ${updaterPod} to complete"
            while [[ $(kubectl -n default get pod ${updaterPod} -o json | jq -r .status.phase) != "Failed" ]] && kubectl -n default get pod | grep ${updaterPod}; do sleep 10; done
            echo "Pod ${updaterPod} is complete"
            sleep 15
          fi 

          kubectl wait -l app=private-worker-agent --for=condition=ready pod --timeout=-1s -n tekton-pipelines
          kubectl wait -l app=tekton-pipelines-controller --for=condition=ready pod --timeout=-1s -n tekton-pipelines
          kubectl wait -l app=tekton-pipelines-webhook --for=condition=ready pod --timeout=-1s -n tekton-pipelines

          kubectl patch workeragent $(kubectl get workeragents.devops.cloud.ibm.com -oname | sed "s/.*\///") --type='merge' -p '{"spec": {"paused": false}}'

          kubectl describe workeragents
          kubectl get po -n tekton-pipelines
          kubectl get deployments -o wide -n tekton-pipelines
          kubectl get ds kata-deploy -o wide -n kube-system

          echo "Update complete on cluster ${CLUSTER_NAME}"
